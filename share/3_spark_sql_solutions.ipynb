{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOKBpjxMV-h0"
   },
   "source": [
    "# Pyspark and SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yl1TrUlfV-h3"
   },
   "source": [
    "Create DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JOJoA7xUV-h4",
    "outputId": "c8642d66-b730-4fb2-b11a-af3f7300f26d"
   },
   "outputs": [],
   "source": [
    "# Get your Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VWzl8mI0V-h5",
    "outputId": "7265afe4-e348-4ea1-9e54-ce89c4ae5cc0"
   },
   "outputs": [],
   "source": [
    "# Create Example Data - Departments and Employees\n",
    "\n",
    "# Create the Departments\n",
    "department1 = Row(id='123456', name='Computer Science')\n",
    "department2 = Row(id='789012', name='Mechanical Engineering')\n",
    "department3 = Row(id='345678', name='Theater and Drama')\n",
    "department4 = Row(id='901234', name='Indoor Recreation')\n",
    "\n",
    "# Create the Employees\n",
    "Employee = Row(\"firstName\", \"lastName\", \"email\", \"salary\")\n",
    "employee1 = Employee('michael', 'armbrust', 'no-reply@berkeley.edu', 100000)\n",
    "employee2 = Employee('xiangrui', 'meng', 'no-reply@stanford.edu', 120000)\n",
    "employee3 = Employee('matei', None, 'no-reply@waterloo.edu', 140000)\n",
    "employee4 = Employee(None, 'wendell', 'no-reply@berkeley.edu', 160000)\n",
    "\n",
    "# Create the DepartmentWithEmployees instances from Departments and Employees\n",
    "departmentWithEmployees1 = Row(department=department1, employees=[employee1, employee2])\n",
    "departmentWithEmployees2 = Row(department=department2, employees=[employee3, employee4])\n",
    "departmentWithEmployees3 = Row(department=department3, employees=[employee1, employee4])\n",
    "departmentWithEmployees4 = Row(department=department4, employees=[employee2, employee3])\n",
    "\n",
    "print(department1)\n",
    "print(employee2)\n",
    "print(departmentWithEmployees1.employees[0].email)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qAIcZvlpV-h5"
   },
   "source": [
    "Create DataFrames from a list of the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0KlY_RfoV-h5",
    "outputId": "682a2751-ee82-4a93-96a1-b3edd2656fe4"
   },
   "outputs": [],
   "source": [
    "departmentsWithEmployeesSeq1 = [departmentWithEmployees1, departmentWithEmployees2]\n",
    "df1 = spark.createDataFrame(departmentsWithEmployeesSeq1)\n",
    "\n",
    "df1.show()\n",
    "\n",
    "departmentsWithEmployeesSeq2 = [departmentWithEmployees3, departmentWithEmployees4]\n",
    "df2 = spark.createDataFrame(departmentsWithEmployeesSeq2)\n",
    "\n",
    "df2.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yj-2WqDIV-h6"
   },
   "source": [
    "# Work with DataFrames\n",
    "## Union two DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dCZm6hSgV-h6",
    "outputId": "da92021d-46cb-4bb2-c129-5d5d333b5594"
   },
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dlwl32JwV-h7"
   },
   "source": [
    "Write the unioned DataFrame to a Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "di7mDQ04V-h7",
    "outputId": "6783cdf7-809a-46de-eebb-d9f9fb709cbf"
   },
   "outputs": [],
   "source": [
    "# Remove the file if it exists\n",
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COlkOhnzV-h7"
   },
   "source": [
    "Read a DataFrame from the Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fYxLPQd_V-h7",
    "outputId": "b19723ed-d19e-4b6e-9b92-3ff4106d5738"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytQb8OhsV-h8"
   },
   "source": [
    "## Explode the employees column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4Psu1TcV-h8",
    "outputId": "b30c226c-84bc-4657-b08e-03cf61e7d11b"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9evu6RhV-h8"
   },
   "source": [
    "## Use filter() to return the rows that match a predicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5e2UmwPpV-h8",
    "outputId": "60d6a8d4-c5aa-46a8-c5f5-422c57b46e20"
   },
   "outputs": [],
   "source": [
    "# TODO Filter on firstname xiangrui\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzxObwndV-h9"
   },
   "source": [
    "Replace null values with -- using DataFrame Na function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PVSdUxywV-h9",
    "outputId": "187a29eb-6387-46a0-d8ad-8e10f820c061"
   },
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewIAO-dBV-h-"
   },
   "source": [
    "Retrieve only rows with missing firstName or lastName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IcV9EKVdV-h-",
    "outputId": "18f3fc5f-3342-4f4b-8d84-a6c80319644b"
   },
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnSt_-t6V-h-"
   },
   "source": [
    "Example aggregations using agg() and countDistinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xx2jq6ZQV-h-",
    "outputId": "b7bf6367-84f8-4092-f437-9b662f9da001"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "countDistinctDF = explodeDF.select(\"firstName\", \"lastName\")\\\n",
    "  .groupBy(\"firstName\", \"lastName\")\\\n",
    "  .agg(countDistinct(\"firstName\"))\n",
    "\n",
    "countDistinctDF.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93YOKKiVV-h-"
   },
   "source": [
    "## Compare the DataFrame and SQL query physical plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56207udwV-h-",
    "outputId": "0e8936d4-bb8b-45c0-e834-1ee411992999"
   },
   "outputs": [],
   "source": [
    "countDistinctDF.explain()\n",
    "# register the DataFrame as a temp table so that we can query it using SQL\n",
    "# TODO\n",
    "\n",
    "# Perform the same query as the DataFrame above and return ``explain``\n",
    "countDistinctDF_sql = spark.sql(\"# TODO\")\n",
    "\n",
    "countDistinctDF_sql.explain()\n",
    "\n",
    "# Should be the same !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qM7rZ5DV-h_"
   },
   "source": [
    "Sum up all the salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WjvbhMSsV-h_",
    "outputId": "659bec51-4038-44a8-b6c3-eedf93e5f32c"
   },
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_ENnWDtV-h_"
   },
   "source": [
    "Print the summary statistics for the salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXn_gl6QV-h_",
    "outputId": "746758e8-8796-47a6-dc6a-8a6898955832"
   },
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/Vincent-Initiative/formation_utt_solutions/blob/main/solutions/2_spark_sql_solutions.ipynb",
     "timestamp": 1699204741200
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
